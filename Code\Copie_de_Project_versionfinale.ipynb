{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copie de Project code 2 amélioration",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NFroehl/DMML2021_Nestle/blob/main/Code%5CCopie_de_Project_versionfinale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9JGePu64Ml4"
      },
      "source": [
        "#Project : Nestle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCrMlTr04TlH"
      },
      "source": [
        "Here are the important libraries that we will use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdiuxCSZ4ZXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb5045f6-489d-4e5c-d4e7-4ff07db93e1b"
      },
      "source": [
        "# Install and update spaCy\n",
        "!pip install -U spacy\n",
        "\n",
        "# Download the french language model\n",
        "!python -m spacy download fr"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'fr' are deprecated. Please use the\n",
            "full pipeline package name 'fr_core_news_sm' instead.\u001b[0m\n",
            "Collecting fr-core-news-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.2.0/fr_core_news_sm-3.2.0-py3-none-any.whl (17.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4 MB 101.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from fr-core-news-sm==3.2.0) (3.2.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.8.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.19.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (8.0.13)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->fr-core-news-sm==3.2.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries:\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import string\n",
        "from spacy.lang.fr.stop_words import STOP_WORDS\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "swPwmYZXXHMS"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMdv9sJ9Z_KT"
      },
      "source": [
        "#1) Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##a) Import Data"
      ],
      "metadata": {
        "id": "CdYhF9oTRzoh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA2Prjju4l2q"
      },
      "source": [
        "First, we read the Training Data using the download link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "igMYiUZi4kCn",
        "outputId": "1c87e291-d5f1-4e8d-dab0-e11dddefa6a0"
      },
      "source": [
        "# Read the data:\n",
        "\n",
        "# We take the url to doawnload the training data:\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/NFroehl/DMML2021_Nestle/74eb14159f5f045d427350358637df31b81ea73b/data/training_data.csv\"\n",
        "Training_Data = pd.read_csv(url, delimiter=\",\")\n",
        "Training_Data.head()"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Les coûts kilométriques réels peuvent diverger...</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Le bleu, c'est ma couleur préférée mais je n'a...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Le test de niveau en français est sur le site ...</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Est-ce que ton mari est aussi de Boston?</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dans les écoles de commerce, dans les couloirs...</td>\n",
              "      <td>B1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                           sentence difficulty\n",
              "0   0  Les coûts kilométriques réels peuvent diverger...         C1\n",
              "1   1  Le bleu, c'est ma couleur préférée mais je n'a...         A1\n",
              "2   2  Le test de niveau en français est sur le site ...         A1\n",
              "3   3           Est-ce que ton mari est aussi de Boston?         A1\n",
              "4   4  Dans les écoles de commerce, dans les couloirs...         B1"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCANeI34D-l0"
      },
      "source": [
        "We get some informations about the Training Data in order to see how good they are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRz_PoSZ4vGf",
        "outputId": "e8d975cb-cb36-45e5-c080-0dad85fb74aa"
      },
      "source": [
        "Training_Data.info()"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4800 entries, 0 to 4799\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   id          4800 non-null   int64 \n",
            " 1   sentence    4800 non-null   object\n",
            " 2   difficulty  4800 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 112.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed = 0"
      ],
      "metadata": {
        "id": "n36QE1U_ILHU"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkaocCH34v7s",
        "outputId": "409a4b6c-80f3-4cd9-e9e8-ae02aad5975f"
      },
      "source": [
        "# Base rate: the data-set is balanced\n",
        "Training_Data.difficulty.value_counts()/Training_Data.shape[0] #the baserate is 0.06973"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A1    0.169375\n",
              "C2    0.168125\n",
              "C1    0.166250\n",
              "B1    0.165625\n",
              "A2    0.165625\n",
              "B2    0.165000\n",
              "Name: difficulty, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHYFSLHiT3OU"
      },
      "source": [
        "Then, we read the Test Data using also the download link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "mWD4kLmVUA3A",
        "outputId": "906f8d63-50bc-4355-81c7-e7539cab2e48"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/NFroehl/DMML2021_Nestle/main/data/unlabelled_test_data.csv\"\n",
        "Test_Data = pd.read_csv(url, delimiter=\",\")\n",
        "Test_Data.head(2)\n",
        "#Test_Data.sentence.shape"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Nous dûmes nous excuser des propos que nous eû...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Vous ne pouvez pas savoir le plaisir que j'ai ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                           sentence\n",
              "0   0  Nous dûmes nous excuser des propos que nous eû...\n",
              "1   1  Vous ne pouvez pas savoir le plaisir que j'ai ..."
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##b) Vectorize Data"
      ],
      "metadata": {
        "id": "KFkF-FS2SQ1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do the regression, even without cleaning the data, we need a tokenizer function."
      ],
      "metadata": {
        "id": "CeTkkgy_Q5In"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdoJTkyO5IdP"
      },
      "source": [
        "# Let's implement the tokenizer function:\n",
        "\n",
        "# Load French language model:\n",
        "sp = spacy.load('fr_core_news_sm')\n",
        "\n",
        "# Tokenizer function:\n",
        "def spacy_tokenizer1(sentence):\n",
        "    # Create token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = sp(sentence)\n",
        "    # Return list of tokens\n",
        "    return mytokens"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2) Classification without Data Cleaning"
      ],
      "metadata": {
        "id": "XShv4w7nSeU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each method, we will do hyperparametrization for the TfidVectorizer() function. We will do it on the analyzers word and char."
      ],
      "metadata": {
        "id": "G7dVMzNVxzuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To compare all methods, we will create a list of accuracies depending on parameters and methods:\n",
        "TotalResult = []"
      ],
      "metadata": {
        "id": "qCr3SgtQzTUP"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##a) Split Data"
      ],
      "metadata": {
        "id": "_eYvWw-kTBXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select features\n",
        "X = Training_Data['sentence'] # the features we want to analyze\n",
        "y = Training_Data['difficulty'] # the labels, or answers, we want to test against"
      ],
      "metadata": {
        "id": "WPuEQOxQUY0B"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train/test split function\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train/test splitting code\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
      ],
      "metadata": {
        "id": "WCJcRAzPUTvQ"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##b) Function to evaluate the following models"
      ],
      "metadata": {
        "id": "YJp2LbFNXYFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the models\n",
        "def evaluate(true, pred):\n",
        "    precision = precision_score(true, pred, average='micro')\n",
        "    recall = recall_score(true, pred, average='micro')\n",
        "    f1 = f1_score(true, pred, average='micro')\n",
        "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(true, pred)}\")\n",
        "    print(f\"ACCURACY SCORE:\\n{accuracy_score(true, pred):.4f}\")\n",
        "    print(f\"CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "mzlltioEXg4u"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exzyB7GJ8j-9"
      },
      "source": [
        "##c) Classification of the reviews using Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Define list for result\n",
        "analyzer = ['word', 'char']\n",
        "result = []\n",
        "\n",
        "for x in analyzer:\n",
        "\n",
        "    # Redefine vectorizer\n",
        "    tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer1, \n",
        "                                   analyzer=x)\n",
        "\n",
        "    # Define classifier\n",
        "    classifier = LogisticRegression()\n",
        "\n",
        "    # Create pipeline\n",
        "    pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "    # Fit model on training set\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = pipe.predict(X_test)\n",
        "\n",
        "    # Print accuracy on test set\n",
        "    print(\"Analyzer: \", x)\n",
        "    evaluate(y_test, y_pred)\n",
        "    print(\"-----------------------\")\n",
        "\n",
        "    # Append to result\n",
        "    result.append([x, accuracy_score(y_test, y_pred)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcY0JBJkpZ_Z",
        "outputId": "4cd44546-3224-4f97-b77e-4479e74e6967"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzer:  word\n",
            "CONFUSION MATRIX:\n",
            "[[  0   0   0   0   0 174]\n",
            " [  0   0   0   0   0 161]\n",
            " [  0   0   0   0   0 159]\n",
            " [  0   0   0   0   0 154]\n",
            " [  0   0   0   0   0 160]\n",
            " [  0   0   0   0   0 152]]\n",
            "ACCURACY SCORE:\n",
            "0.1583\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.1583\n",
            "\tRecall: 0.1583\n",
            "\tF1_Score: 0.1583\n",
            "-----------------------\n",
            "Analyzer:  char\n",
            "CONFUSION MATRIX:\n",
            "[[113  25  17  12   2   5]\n",
            " [ 38  57  43   8   4  11]\n",
            " [ 17  31  54  21  12  24]\n",
            " [ 11   1  11  51  34  46]\n",
            " [  1   1  10  35  59  54]\n",
            " [  4   2   9  18  26  93]]\n",
            "ACCURACY SCORE:\n",
            "0.4448\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4448\n",
            "\tRecall: 0.4448\n",
            "\tF1_Score: 0.4448\n",
            "-----------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TotalResult.append(result)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSEM7z1xv47p",
        "outputId": "1b2ad958-68b2-43d4-9921-11dbe8b928b1"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['word', 0.15833333333333333], ['char', 0.44479166666666664]]"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqeWpXWdJkEJ"
      },
      "source": [
        "##d) Classification of the reviews using KNN Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we tun hyperparameters with GridSearch (for n_neighbors, p and weights)."
      ],
      "metadata": {
        "id": "fCHh0TBVvrFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Define parameters to test\n",
        "grid = {'n_neighbors':np.arange(1,7),\n",
        "        'p':np.arange(1,3),\n",
        "        'weights':['uniform','distance']\n",
        "       }\n",
        "\n",
        "# Define and fit model\n",
        "knn = KNeighborsClassifier()\n",
        "knn_cv = GridSearchCV(knn, grid, cv=10)\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', knn_cv)])\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "nb = knn_cv.best_params_['n_neighbors']\n",
        "p = knn_cv.best_params_['p']\n",
        "w = knn_cv.best_params_['weights']\n",
        "\n",
        "# Print results\n",
        "print(\"Hyperparameters:\", knn_cv.best_params_)\n",
        "print(\"Train Score:\", round(knn_cv.best_score_, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubm37eZvvtC7",
        "outputId": "ab39e7f7-a791-4f37-8bb6-4ad4deb472df"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'n_neighbors': 4, 'p': 1, 'weights': 'distance'}\n",
            "Train Score: 0.3539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we do the regression with the best parameters."
      ],
      "metadata": {
        "id": "zPACyA0-zET2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define list for result\n",
        "analyzer = ['word', 'char']\n",
        "result = []\n",
        "\n",
        "for x in analyzer:\n",
        "\n",
        "    # Redefine vectorizer\n",
        "    tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer1, \n",
        "                                   analyzer=x)\n",
        "\n",
        "    # Define classifier\n",
        "    classifier = KNeighborsClassifier(n_neighbors=nb, p = p, weights = w)\n",
        "\n",
        "    # Create pipeline\n",
        "    pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "    # Fit model on training set\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = pipe.predict(X_test)\n",
        "\n",
        "    # Print accuracy on test set\n",
        "    print(\"Analyzer: \", x)\n",
        "    evaluate(y_test, y_pred)\n",
        "    print(\"-----------------------\")\n",
        "\n",
        "    # Append to result\n",
        "    result.append([x, accuracy_score(y_test, y_pred)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMiU3jWF0GsY",
        "outputId": "f34239d3-38f7-4674-9b50-33322af62a2f"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzer:  word\n",
            "CONFUSION MATRIX:\n",
            "[[174   0   0   0   0   0]\n",
            " [161   0   0   0   0   0]\n",
            " [159   0   0   0   0   0]\n",
            " [154   0   0   0   0   0]\n",
            " [160   0   0   0   0   0]\n",
            " [152   0   0   0   0   0]]\n",
            "ACCURACY SCORE:\n",
            "0.1812\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.1812\n",
            "\tRecall: 0.1812\n",
            "\tF1_Score: 0.1813\n",
            "-----------------------\n",
            "Analyzer:  char\n",
            "CONFUSION MATRIX:\n",
            "[[84 38 27  7  6 12]\n",
            " [28 50 39 21 11 12]\n",
            " [23 25 39 31 21 20]\n",
            " [ 4 10 20 31 47 42]\n",
            " [ 3  4 14 22 54 63]\n",
            " [ 1  4  7 18 46 76]]\n",
            "ACCURACY SCORE:\n",
            "0.3479\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.3479\n",
            "\tRecall: 0.3479\n",
            "\tF1_Score: 0.3479\n",
            "-----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TotalResult.append(result)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT9AgTRq0ro0",
        "outputId": "d6982245-2be0-4c08-8f62-447650718a22"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['word', 0.18125], ['char', 0.34791666666666665]]"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVw0lRgtRPAd"
      },
      "source": [
        "##e) Classification of the reviews using Decision Tree Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we tun hyperparameters with GridSearch (for depth)."
      ],
      "metadata": {
        "id": "-AI-DDQItF7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Grid Search - tuning tree depth\n",
        "\n",
        "# Define parameter to test\n",
        "grid = {'max_depth':np.arange(1,10)}\n",
        "\n",
        "# Define and fit model\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "tree_cv = GridSearchCV(tree, grid, cv=5)\n",
        "\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', tree_cv)])\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "d = tree_cv.best_params_\n",
        "\n",
        "# Print results\n",
        "print(\"Hyperparameters:\", tree_cv.best_params_)\n",
        "print(\"Train Score:\", round(tree_cv.best_score_, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8nZpkHytaqZ",
        "outputId": "e95b22fa-bd9b-47c4-f5fc-a10aa87cae79"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'max_depth': 5}\n",
            "Train Score: 0.3583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we do the regression with the best parameter."
      ],
      "metadata": {
        "id": "zhmdsMswuBw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define list for result\n",
        "analyzer = ['word', 'char']\n",
        "result = []\n",
        "\n",
        "for x in analyzer:\n",
        "\n",
        "    # Redefine vectorizer\n",
        "    tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer1, \n",
        "                                   analyzer=x)\n",
        "\n",
        "    # Define classifier\n",
        "    classifier = DecisionTreeClassifier(max_depth=6, random_state=72) #best parameter we found\n",
        "\n",
        "    # Create pipeline\n",
        "    pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "    # Fit model on training set\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = pipe.predict(X_test)\n",
        "\n",
        "    # Print accuracy on test set\n",
        "    print(\"Analyzer: \", x)\n",
        "    evaluate(y_test, y_pred)\n",
        "    print(\"-----------------------\")\n",
        "\n",
        "    # Append to result\n",
        "    result.append([x, accuracy_score(y_test, y_pred)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrCUF1o1009u",
        "outputId": "40e0c74e-3ce2-4f76-ddd3-173591f343f2"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzer:  word\n",
            "CONFUSION MATRIX:\n",
            "[[  0   0   0   0   0 174]\n",
            " [  0   0   0   0   0 161]\n",
            " [  0   0   0   0   0 159]\n",
            " [  0   0   0   0   0 154]\n",
            " [  0   0   0   0   0 160]\n",
            " [  0   0   0   0   0 152]]\n",
            "ACCURACY SCORE:\n",
            "0.1583\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.1583\n",
            "\tRecall: 0.1583\n",
            "\tF1_Score: 0.1583\n",
            "-----------------------\n",
            "Analyzer:  char\n",
            "CONFUSION MATRIX:\n",
            "[[84 43 40  4  0  3]\n",
            " [31 44 74  9  0  3]\n",
            " [ 8 23 99 13 12  4]\n",
            " [ 4  6 45 40 40 19]\n",
            " [ 2  3 29 30 63 33]\n",
            " [ 1  2 29 13 52 55]]\n",
            "ACCURACY SCORE:\n",
            "0.4010\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4010\n",
            "\tRecall: 0.4010\n",
            "\tF1_Score: 0.4010\n",
            "-----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TotalResult.append(result)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNzKZoLE1bC3",
        "outputId": "43ab379f-a7ba-4033-8220-d157f11e2060"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['word', 0.15833333333333333], ['char', 0.4010416666666667]]"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##f) Classification of the reviews using Random Forest Regression"
      ],
      "metadata": {
        "id": "hQgnfaQAbHm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Define list for result\n",
        "analyzer = ['word', 'char']\n",
        "result = []\n",
        "\n",
        "for x in analyzer:\n",
        "\n",
        "    # Redefine vectorizer\n",
        "    tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer1, \n",
        "                                   analyzer=x)\n",
        "\n",
        "    # Define classifier\n",
        "    classifier = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "    # Create pipeline\n",
        "    pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "    # Fit model on training set\n",
        "    pipe.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = pipe.predict(X_test)\n",
        "\n",
        "    # Print accuracy on test set\n",
        "    print(\"Analyzer: \", x)\n",
        "    evaluate(y_test, y_pred)\n",
        "    print(\"-----------------------\")\n",
        "\n",
        "    # Append to result\n",
        "    result.append([x, accuracy_score(y_test, y_pred)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbHLIFAa1nfw",
        "outputId": "012fa57d-f794-4058-cd8b-75d73b455660"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzer:  word\n",
            "CONFUSION MATRIX:\n",
            "[[  0   0   0   0   0 174]\n",
            " [  0   0   0   0   0 161]\n",
            " [  0   0   0   0   0 159]\n",
            " [  0   0   0   0   0 154]\n",
            " [  0   0   0   0   0 160]\n",
            " [  0   0   0   0   0 152]]\n",
            "ACCURACY SCORE:\n",
            "0.1583\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.1583\n",
            "\tRecall: 0.1583\n",
            "\tF1_Score: 0.1583\n",
            "-----------------------\n",
            "Analyzer:  char\n",
            "CONFUSION MATRIX:\n",
            "[[116  36  16   2   2   2]\n",
            " [ 44  63  42   6   2   4]\n",
            " [ 23  41  53  19  12  11]\n",
            " [  9   9  17  57  43  19]\n",
            " [  3   2  12  38  64  41]\n",
            " [  4   4  11  25  31  77]]\n",
            "ACCURACY SCORE:\n",
            "0.4479\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.4479\n",
            "\tRecall: 0.4479\n",
            "\tF1_Score: 0.4479\n",
            "-----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TotalResult.append(result)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQQQgXcp2Rrb",
        "outputId": "6304831a-2daa-42f3-f539-123f5ececc7b"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['word', 0.15833333333333333], ['char', 0.4479166666666667]]"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##g) Results"
      ],
      "metadata": {
        "id": "kS5-TBZ82TlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare our previous results to choose which method we are going to keep for the next part (with data cleaning)."
      ],
      "metadata": {
        "id": "Gzd49wLN2iVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I import the library that I need to plot :\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# I build the lists which contains the accuracy for each method :\n",
        "n = len(TotalResult)\n",
        "TestAccuracyWord = [TotalResult[i][0][1] for i in range(n)]\n",
        "TestAccuracyChar = [TotalResult[i][1][1] for i in range(n)]\n",
        "x = [i for i in range(1,n+1)]\n",
        "\n",
        "# I plot the lists and I put a name for each point :\n",
        "labels = ['Logistic', 'KNN', 'DecTree', 'RandForest']\n",
        "\n",
        "plt.title('Accuracy')\n",
        "plt.plot(x, TestAccuracyWord, label = 'Word')\n",
        "plt.plot(x, TestAccuracyChar, label = 'Char')\n",
        "plt.legend()\n",
        "plt.xticks(x, labels, rotation = 45)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "lAL9O0hB2yRj",
        "outputId": "8848049e-7e19-4555-e7e4-3c56c05d6380"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TotalResult"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OZz3_8v5eVj",
        "outputId": "536baf3c-501c-49da-c97f-b316ab5efc6e"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[['word', 0.15833333333333333], ['char', 0.44479166666666664]],\n",
              " [['word', 0.18125], ['char', 0.34791666666666665]],\n",
              " [['word', 0.15833333333333333], ['char', 0.4010416666666667]],\n",
              " [['word', 0.15833333333333333], ['char', 0.4479166666666667]]]"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the list and the graph, we decide to continue to work with Logistic Regression and Analyzer = 'char'. Random Forest has also a very good accuracy. Maybe we will try it too."
      ],
      "metadata": {
        "id": "Z-BF-mFW5jwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3) Classification with Data Cleaning"
      ],
      "metadata": {
        "id": "UOBzI0sX53a9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##a) Data Cleaning function et vectorization"
      ],
      "metadata": {
        "id": "XqiTex2K6GN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use nltk package for cleaning"
      ],
      "metadata": {
        "id": "hsU9-k_XLkja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#other tokenizer function\n",
        "\n",
        "#celle là est meilleure\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "# Define cleaning function\n",
        "def data_cleaner(sms):\n",
        "\n",
        "    # Define stopwords\n",
        "    stop_words = stopwords.words('french')\n",
        "\n",
        "    # Define tokenizer and stemmer\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    from nltk.stem import PorterStemmer\n",
        "    \n",
        "    # Remove digits\n",
        "    sms = re.sub(r\"\\d+\",\"\", sms)\n",
        "    \n",
        "    # Lowercase\n",
        "    sms = sms.lower()\n",
        "    \n",
        "    # Remove punctuation\n",
        "    sms = re.sub(r\"[^\\w\\s\\d]\",\"\", sms)\n",
        "\n",
        "   # Remove stop words\n",
        "    sms = sms.split()\n",
        "    sms = \" \".join([word for word in sms if not word in stop_words])\n",
        "    \n",
        "    # Tokenize\n",
        "    sms = word_tokenize(sms)\n",
        "    \n",
        "    # Stemming\n",
        "    ps = PorterStemmer()\n",
        "    sms = [ps.stem(word) for word in sms]\n",
        "    \n",
        "    return sms "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbFufAzJS1tA",
        "outputId": "5363e016-61cd-4cd6-e2ba-0833c267e13e"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean X_train \n",
        "X_train.apply(data_cleaner)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJg9g117HYZ2",
        "outputId": "5a028397-4557-4f26-a359-605c4ad11de1"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3925    [jai, vu, cett, grand, imag, litali, relev, fa...\n",
              "2070    [cett, somm, comprend, dépens, délectricité, c...\n",
              "4211                 [ira, voir, maman, semain, prochain]\n",
              "1452    [cadr, dune, recherch, sociolinguistiqu, urbai...\n",
              "1881                                   [just, petit, peu]\n",
              "                              ...                        \n",
              "3079    [aristocr, naissanc, haîssait, instinct, quatr...\n",
              "3951                                         [jai, froid]\n",
              "2885    [rien, dextraordinair, quand, vit, sud, leurop...\n",
              "3941    [éclair, cett, lueur, chemin, crépusculair, mè...\n",
              "4568    [quartier, certain, voisin, sentend, ouvrir, p...\n",
              "Name: sentence, Length: 3840, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is not perfect mais already great. We further use DOC2VEC to vectorize"
      ],
      "metadata": {
        "id": "Ds9LwiLfLxOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "sample_tagged = Training_Data.apply(lambda r: TaggedDocument(words=data_cleaner(r['sentence']), tags=[r.difficulty]),axis=1)\n",
        "#test_tagged = Test_Data.apply(lambda r: TaggedDocument(words=data_cleaner(r['sentence']), tags = None), axis=1)\n"
      ],
      "metadata": {
        "id": "0XcLknLezdJC"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tagged.values[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SLxy8iXYOCN",
        "outputId": "6a580640-2a12-4691-c2b5-78f4addb6723"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaggedDocument(words=['bonjour', 'bonn', 'anné'], tags=['A1'])"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split - same split as before\n",
        "train_tagged, test_tagged = train_test_split(sample_tagged, test_size=0.2, random_state=1234)"
      ],
      "metadata": {
        "id": "ujl_d8HbxLWm"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_tagged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGR4O4PrYZyQ",
        "outputId": "71ff1bfe-97af-4ec2-ca5f-166cd9e289af"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4448    ([avant, laisser, parol, monsieur, servat, sau...\n",
              "3022    ([quand, reviendrai, joffrirai, beaucoup, damo...\n",
              "827                         ([beau, succè, destim], [C1])\n",
              "1745    ([clore, cett, monographi, café, constantinopo...\n",
              "4202    ([lune, plu, emblématiqu, mari, sophi, germain...\n",
              "                              ...                        \n",
              "3640                 ([jai, mangé, hamburg, frite], [A1])\n",
              "2229    ([organisé, loccas, e, anniversair, mort, poèt...\n",
              "319     ([noter, lapprentissag, grammair, français, ob...\n",
              "4697    ([lorigin, politiqu, sen, modern, mot, europ, ...\n",
              "1416    ([grand, maison, chien, poisson, deux, chat], ...\n",
              "Length: 960, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Allows to speed up a bit\n",
        "import multiprocessing\n",
        "cores = multiprocessing.cpu_count()"
      ],
      "metadata": {
        "id": "irmVvdz4xBJz"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define Doc2Vec and build vocabulary\n",
        "from gensim.models import Doc2Vec\n",
        "\n",
        "model_dbow = Doc2Vec(dm=0, vector_size=30, negative=6, hs=0, min_count=1, sample=0, workers=cores, epoch=300)\n",
        "model_dbow.build_vocab([x for x in sample_tagged.values])\n"
      ],
      "metadata": {
        "id": "6GZksW4dw5qS"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now train the distributed bag of words model. In short, it trains a neural network and the optimal weights are the coefficients of the vectors of the documents. Therefore, similar documents will be close to each other in the N-dimentional space (N being the size of the vectors)."
      ],
      "metadata": {
        "id": "Zj9Eeyt4Yrwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train distributed Bag of Word model\n",
        "model_dbow.train(sample_tagged, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)"
      ],
      "metadata": {
        "id": "UOrAmzw96vo_"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select X and y\n",
        "def vec_for_learning(model, tagged_docs):\n",
        "    sents = tagged_docs.values\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=100)) for doc in sents])\n",
        "    return targets, regressors\n",
        "    \n",
        "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
        "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
      ],
      "metadata": {
        "id": "GRZe4FAg64Oe"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgqsvLziZJdP",
        "outputId": "990efdb3-f979-41e8-b103-58b7d44b1b51"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0.45130193, -0.00456627,  0.4897842 , -0.47425115, -0.6346759 ,\n",
              "         1.4173802 ,  0.37663952, -0.8962783 , -1.1287858 ,  0.54514503,\n",
              "        -0.93053687,  1.091367  , -1.69588   ,  0.8894113 , -0.20300531,\n",
              "         0.9029507 ,  0.54808605,  0.19763283, -0.6599458 , -0.08869366,\n",
              "         0.5209002 , -0.84276456, -0.27474204,  1.4353262 ,  0.24260049,\n",
              "         0.48954898, -0.39823252, -0.33914727,  0.28934687, -0.6355274 ],\n",
              "       dtype=float32),\n",
              " array([ 0.44197   , -0.1804826 ,  0.64520806, -0.4110789 , -0.8712233 ,\n",
              "         1.2134622 ,  0.6077104 , -0.7538035 , -0.56493276,  0.53218967,\n",
              "        -1.0820745 ,  1.1752875 , -1.411636  ,  0.5838171 , -0.23998481,\n",
              "         1.0389953 ,  0.48837554, -0.13878368, -0.43517706, -0.11196656,\n",
              "         0.69720507, -0.9866815 , -0.20038159,  1.4116933 ,  0.6155288 ,\n",
              "         0.03276075, -0.48087478, -0.06343427,  0.5571027 , -0.6628881 ],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) Logistic Regression with DOC2VEC"
      ],
      "metadata": {
        "id": "dBDjGev8bpHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model on training set\n",
        "logreg = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = logreg.predict(X_test)"
      ],
      "metadata": {
        "id": "RBSo72HQEzqk"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print accuracy on test set \n",
        "evaluate(y_test, y_pred)\n",
        "#we have an accuracy of 0.7333"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYUX424IcCOG",
        "outputId": "060ff836-ab21-4cd2-fd0b-dcb3b87b145d"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFUSION MATRIX:\n",
            "[[124  27  12   2   1   0]\n",
            " [ 40  89  25   1   1   0]\n",
            " [ 17  29 111   9   0   1]\n",
            " [  3   1  14 115  16   6]\n",
            " [  2   4   1  16 126   8]\n",
            " [  0   1   5   8   6 139]]\n",
            "ACCURACY SCORE:\n",
            "0.7333\n",
            "CLASSIFICATION REPORT:\n",
            "\tPrecision: 0.7333\n",
            "\tRecall: 0.7333\n",
            "\tF1_Score: 0.7333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4) Final Classifation for Kaggle"
      ],
      "metadata": {
        "id": "qE_vL4j1diHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a better accuracy, we use the whole Train Data to do the final regression.\n"
      ],
      "metadata": {
        "id": "gpJ6HExvdpDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train distributed Bag of Word model\n",
        "model_dbow.train(sample_tagged, total_examples=model_dbow.corpus_count, epochs=model_dbow.epochs)"
      ],
      "metadata": {
        "id": "cAp5dLDXgsY6"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare train data\n",
        "y_train_Kaggle, X_train_Kaggle = vec_for_learning(model_dbow, sample_tagged)"
      ],
      "metadata": {
        "id": "1A3xMxCKeAxR"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare test data\n",
        "\n",
        "test_tagged = Test_Data.apply(lambda r: TaggedDocument(words=data_cleaner(r['sentence']), tags = None), axis=1)"
      ],
      "metadata": {
        "id": "3_Qy9QjzfcQI"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To prepare the test data\n",
        "def vec_for_predicting(model, tagged_docs):\n",
        "    sents = tagged_docs.values\n",
        "    regressors = [(model.infer_vector(doc.words, steps=100)) for doc in sents]\n",
        "    return regressors"
      ],
      "metadata": {
        "id": "MJLjOAMYf43B"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_test_Kaggle = vec_for_predicting(model_dbow, test_tagged)"
      ],
      "metadata": {
        "id": "XHKkVNgX92TM"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model on training set\n",
        "logreg = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "logreg.fit(X_train_Kaggle, y_train_Kaggle)"
      ],
      "metadata": {
        "id": "6HsW28Wr9pwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7821e0c5-be77-4785-a5c2-981b66a3c409"
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "LogRegPred = logreg.predict(X_test_Kaggle)"
      ],
      "metadata": {
        "id": "iUEbIIXvAPYH"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LogisticReg_pred = pd.DataFrame(LogRegPred)"
      ],
      "metadata": {
        "id": "bdJpZCvMAblG"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LogisticReg_pred.columns = ['difficulty']\n",
        "LogisticReg_pred.insert(0, 'id', [i for i in range(1200)])"
      ],
      "metadata": {
        "id": "2ITXkpRlBgyi"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LogisticReg_pred.to_csv('LogisticReg_prediction.csv', header = True, index = False)"
      ],
      "metadata": {
        "id": "3RRCPRbeAoYA"
      },
      "execution_count": 274,
      "outputs": []
    }
  ]
}